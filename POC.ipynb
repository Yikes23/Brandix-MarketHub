{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yikes23/Brandix-MarketHub/blob/main/POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ba6PGCvG7iFO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.distributions import Normal\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_GplYhzdkgv"
      },
      "source": [
        "### Loading and preprocessing MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KhOy8Gkb7Sq2"
      },
      "outputs": [],
      "source": [
        "def fetch_mnist():\n",
        "  trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "  dataset_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=trans_mnist)\n",
        "  dataset_test = datasets.MNIST('./data/mnist/', train=False, download=True, transform=trans_mnist)\n",
        "  return dataset_train, dataset_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK5khNiaJ8eZ"
      },
      "source": [
        "### VAE components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "q_1FMGBNoeCS"
      },
      "outputs": [],
      "source": [
        "def create_encoder(input_dim, latent_dim):\n",
        "    encoder = nn.Sequential(\n",
        "        nn.Linear(input_dim, 128),\n",
        "        nn.ReLU(inplace=False),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(inplace=False)\n",
        "    )\n",
        "    mean = nn.Linear(64, latent_dim)\n",
        "    logvar = nn.Linear(64, latent_dim)\n",
        "    return encoder, mean, logvar\n",
        "\n",
        "def create_decoder(latent_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(latent_dim, 64),\n",
        "        nn.ReLU(inplace=False),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.ReLU(inplace=False),\n",
        "        nn.Linear(128, output_dim)\n",
        "    )\n",
        "\n",
        "# Reparameterization trick\n",
        "def reparameterize(mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfL9LPO9KR4G"
      },
      "source": [
        "### GAN Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AyTPwlsCKFvT"
      },
      "outputs": [],
      "source": [
        "def create_generator(noise_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(noise_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_dim),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "def create_discriminator(input_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "        nn.Sigmoid()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "5QcTZUnapm_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Local CNN model\n",
        "# class CNN(nn.Module):\n",
        "#   # Designed for MNIST dataset (grayscale images)\n",
        "#   # Input channels: 1 (grayscale)\n",
        "#     def __init__(self, config):\n",
        "#         super(CNN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(config['num_channels'], 10, kernel_size=5)\n",
        "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "#         self.conv2_drop = nn.Dropout2d()\n",
        "#         self.fc1 = nn.Linear(320, 50)\n",
        "#         self.fc2 = nn.Linear(50, config['num_classes'])\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
        "#         x = nn.functional.relu(nn.functional.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "#         x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "#         x = nn.functional.relu(self.fc1(x))\n",
        "#         x = nn.functional.dropout(x, training=self.training)\n",
        "#         x = self.fc2(x)\n",
        "#         return nn.functional.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "T-1reRN5plSR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "pQpEdH9LS5ZO"
      },
      "outputs": [],
      "source": [
        "def training_simulation(config, dataset):\n",
        "    device = torch.device(config['device'])\n",
        "    input_dim = output_dim = config['input_dim']\n",
        "    num_epochs = int(config['num_epochs'])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Initialize models\n",
        "    encoder_base, mean_layer, logvar_layer = create_encoder(input_dim, config['latent_dim'])\n",
        "    decoder_model = create_decoder(config['latent_dim'], output_dim)\n",
        "    gen_model = create_generator(config['noise_dim'], output_dim)\n",
        "    disc_model = create_discriminator(input_dim)\n",
        "\n",
        "    # Move models to device\n",
        "    models = {\n",
        "        'encoder': encoder_base.to(device),\n",
        "        'mean': mean_layer.to(device),\n",
        "        'logvar': logvar_layer.to(device),\n",
        "        'decoder': decoder_model.to(device),\n",
        "        'generator': gen_model.to(device),\n",
        "        'discriminator': disc_model.to(device)\n",
        "    }\n",
        "\n",
        "    ensemble_weights = nn.Parameter(torch.tensor([0.5, 0.5], device=device))\n",
        "\n",
        "    optimizers = {\n",
        "        'vae': optim.Adam(\n",
        "            list(models['encoder'].parameters()) +\n",
        "            list(models['decoder'].parameters()) +\n",
        "            list(models['mean'].parameters()) +\n",
        "            list(models['logvar'].parameters()),\n",
        "            lr=config['lr']\n",
        "        ),\n",
        "        'gen': optim.Adam(models['generator'].parameters(), lr=config['lr']),\n",
        "        'disc': optim.Adam(models['discriminator'].parameters(), lr=config['lr']),\n",
        "        'weights': optim.Adam([ensemble_weights], lr=config['lr'])\n",
        "    }\n",
        "\n",
        "    def vae_loss(real_data, vae_output, mu, logvar):\n",
        "        recon = nn.functional.mse_loss(vae_output, real_data, reduction='sum')\n",
        "        kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return (recon + kl_div) / real_data.size(0)\n",
        "\n",
        "    def compute_outputs(real_data, noise):\n",
        "        # VAE outputs\n",
        "        encoded = models['encoder'](real_data)\n",
        "        mu = models['mean'](encoded)\n",
        "        logvar = models['logvar'](encoded)\n",
        "        z = reparameterize(mu, logvar)\n",
        "        vae_output = models['decoder'](z)\n",
        "\n",
        "        # GAN output - Remove .clone() as it's unnecessary\n",
        "        gan_output = models['generator'](noise)\n",
        "\n",
        "        # Ensemble output with softmax weights\n",
        "        weights = nn.functional.softmax(ensemble_weights, dim=0)\n",
        "\n",
        "        # Create ensemble output without detaching weights\n",
        "        e_output = weights[0] * vae_output + weights[1] * gan_output\n",
        "\n",
        "        return {\n",
        "            'vae_output': vae_output,\n",
        "            'gan_output': gan_output,\n",
        "            'ensemble_output': e_output,\n",
        "            'mu': mu,\n",
        "            'logvar': logvar,\n",
        "            'weights': weights\n",
        "        }\n",
        "\n",
        "    def compute_disc_loss(real_data, fake_data):\n",
        "        real_preds = models['discriminator'](real_data)\n",
        "        # Create a new tensor for fake data predictions instead of detaching\n",
        "        fake_data_pred = models['discriminator'](fake_data)\n",
        "\n",
        "        # Compute losses using mean directly\n",
        "        real_loss = torch.mean(torch.log(real_preds + 1e-8))\n",
        "        fake_loss = torch.mean(torch.log(1 - fake_data_pred + 1e-8))\n",
        "\n",
        "        return -(real_loss + fake_loss)\n",
        "\n",
        "    def compute_gen_loss(fake_data):\n",
        "        fake_preds = models['discriminator'](fake_data)\n",
        "        return -torch.mean(torch.log(fake_preds + 1e-8))\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            real_data = data.view(data.size(0), -1).to(device)\n",
        "            noise = torch.randn(real_data.size(0), config['noise_dim']).to(device)\n",
        "\n",
        "            # Get all outputs\n",
        "            outputs = compute_outputs(real_data, noise)\n",
        "\n",
        "            # VAE update\n",
        "            optimizers['vae'].zero_grad()\n",
        "            vae_loss_val = vae_loss(real_data, outputs['vae_output'], outputs['mu'], outputs['logvar'])\n",
        "            vae_loss_val.backward(retain_graph = True)\n",
        "            optimizers['vae'].step()\n",
        "\n",
        "            # Discriminator update\n",
        "            optimizers['disc'].zero_grad()\n",
        "            d_loss = compute_disc_loss(real_data, outputs['gan_output'])\n",
        "            d_loss.backward(retain_graph = True)\n",
        "            optimizers['disc'].step()\n",
        "\n",
        "            # Generator update\n",
        "            optimizers['gen'].zero_grad()\n",
        "            g_loss = compute_gen_loss(outputs['gan_output'])\n",
        "            g_loss.backward(retain_graph = True)\n",
        "            optimizers['gen'].step()\n",
        "\n",
        "            # Ensemble weights update\n",
        "            optimizers['weights'].zero_grad()\n",
        "\n",
        "            # Recompute outputs for ensemble update to avoid gradient issues\n",
        "            fresh_outputs = compute_outputs(real_data, noise)\n",
        "            ensemble_reconstr_loss = nn.functional.mse_loss(fresh_outputs['ensemble_output'], real_data)\n",
        "            weight_reg = torch.abs(fresh_outputs['weights'].sum() - 1.0)\n",
        "            e_loss = ensemble_reconstr_loss + weight_reg\n",
        "\n",
        "            e_loss.backward()\n",
        "            optimizers['weights'].step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx}]')\n",
        "                print(f'VAE Loss: {vae_loss_val.item():.4f}, '\n",
        "                      f'G Loss: {g_loss.item():.4f}, '\n",
        "                      f'D Loss: {d_loss.item():.4f}')\n",
        "                print(f'Ensemble Loss: {e_loss.item():.4f}')\n",
        "                print(f'Weights: VAE={fresh_outputs[\"weights\"][0].item():.2f}, '\n",
        "                      f'GAN={fresh_outputs[\"weights\"][1].item():.2f}\\n')\n",
        "\n",
        "    return models, ensemble_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ygV5rRbM6hW7",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b76dd28-47c1-44a6-b2e1-128e1d841e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [0]\n",
            "VAE Loss: 827.2452, G Loss: 0.6595, D Loss: 1.3672\n",
            "Ensemble Loss: 1.0462\n",
            "Weights: VAE=0.50, GAN=0.50\n",
            "\n",
            "Epoch [1/10], Step [100]\n",
            "VAE Loss: 631.7201, G Loss: 0.6033, D Loss: 1.2252\n",
            "Ensemble Loss: 0.7998\n",
            "Weights: VAE=0.50, GAN=0.50\n",
            "\n",
            "Epoch [1/10], Step [200]\n",
            "VAE Loss: 569.8990, G Loss: 1.1731, D Loss: 0.5698\n",
            "Ensemble Loss: 0.7730\n",
            "Weights: VAE=0.51, GAN=0.49\n",
            "\n",
            "Epoch [1/10], Step [300]\n",
            "VAE Loss: 517.7458, G Loss: 1.7815, D Loss: 0.3402\n",
            "Ensemble Loss: 0.7036\n",
            "Weights: VAE=0.52, GAN=0.48\n",
            "\n",
            "Epoch [1/10], Step [400]\n",
            "VAE Loss: 513.9258, G Loss: 1.8790, D Loss: 0.3258\n",
            "Ensemble Loss: 0.6804\n",
            "Weights: VAE=0.52, GAN=0.48\n",
            "\n",
            "Epoch [1/10], Step [500]\n",
            "VAE Loss: 458.2980, G Loss: 1.5891, D Loss: 0.5061\n",
            "Ensemble Loss: 0.6221\n",
            "Weights: VAE=0.53, GAN=0.47\n",
            "\n",
            "Epoch [1/10], Step [600]\n",
            "VAE Loss: 435.8460, G Loss: 1.7354, D Loss: 0.3581\n",
            "Ensemble Loss: 0.6081\n",
            "Weights: VAE=0.53, GAN=0.47\n",
            "\n",
            "Epoch [1/10], Step [700]\n",
            "VAE Loss: 391.4464, G Loss: 2.9015, D Loss: 0.0864\n",
            "Ensemble Loss: 0.5540\n",
            "Weights: VAE=0.54, GAN=0.46\n",
            "\n",
            "Epoch [1/10], Step [800]\n",
            "VAE Loss: 404.0859, G Loss: 2.5194, D Loss: 0.1376\n",
            "Ensemble Loss: 0.5778\n",
            "Weights: VAE=0.55, GAN=0.45\n",
            "\n",
            "Epoch [1/10], Step [900]\n",
            "VAE Loss: 381.3635, G Loss: 2.2696, D Loss: 0.1354\n",
            "Ensemble Loss: 0.5493\n",
            "Weights: VAE=0.55, GAN=0.45\n",
            "\n",
            "Epoch [2/10], Step [0]\n",
            "VAE Loss: 389.1660, G Loss: 2.3877, D Loss: 0.1109\n",
            "Ensemble Loss: 0.5656\n",
            "Weights: VAE=0.56, GAN=0.44\n",
            "\n",
            "Epoch [2/10], Step [100]\n",
            "VAE Loss: 353.5790, G Loss: 2.8263, D Loss: 0.0706\n",
            "Ensemble Loss: 0.5405\n",
            "Weights: VAE=0.56, GAN=0.44\n",
            "\n",
            "Epoch [2/10], Step [200]\n",
            "VAE Loss: 344.5868, G Loss: 2.3710, D Loss: 0.1049\n",
            "Ensemble Loss: 0.5278\n",
            "Weights: VAE=0.57, GAN=0.43\n",
            "\n",
            "Epoch [2/10], Step [300]\n",
            "VAE Loss: 342.6844, G Loss: 2.6504, D Loss: 0.0834\n",
            "Ensemble Loss: 0.5008\n",
            "Weights: VAE=0.58, GAN=0.42\n",
            "\n",
            "Epoch [2/10], Step [400]\n",
            "VAE Loss: 351.7189, G Loss: 3.5656, D Loss: 0.0322\n",
            "Ensemble Loss: 0.5282\n",
            "Weights: VAE=0.58, GAN=0.42\n",
            "\n",
            "Epoch [2/10], Step [500]\n",
            "VAE Loss: 336.0038, G Loss: 4.2642, D Loss: 0.0288\n",
            "Ensemble Loss: 0.4708\n",
            "Weights: VAE=0.59, GAN=0.41\n",
            "\n",
            "Epoch [2/10], Step [600]\n",
            "VAE Loss: 321.7243, G Loss: 4.7009, D Loss: 0.0719\n",
            "Ensemble Loss: 0.4485\n",
            "Weights: VAE=0.59, GAN=0.41\n",
            "\n",
            "Epoch [2/10], Step [700]\n",
            "VAE Loss: 317.8204, G Loss: 5.7051, D Loss: 0.0259\n",
            "Ensemble Loss: 0.4667\n",
            "Weights: VAE=0.60, GAN=0.40\n",
            "\n",
            "Epoch [2/10], Step [800]\n",
            "VAE Loss: 310.4230, G Loss: 5.5722, D Loss: 0.0205\n",
            "Ensemble Loss: 0.4600\n",
            "Weights: VAE=0.60, GAN=0.40\n",
            "\n",
            "Epoch [2/10], Step [900]\n",
            "VAE Loss: 318.6410, G Loss: 5.2184, D Loss: 0.0465\n",
            "Ensemble Loss: 0.4632\n",
            "Weights: VAE=0.61, GAN=0.39\n",
            "\n",
            "Epoch [3/10], Step [0]\n",
            "VAE Loss: 303.0289, G Loss: 5.6936, D Loss: 0.0178\n",
            "Ensemble Loss: 0.4309\n",
            "Weights: VAE=0.61, GAN=0.39\n",
            "\n",
            "Epoch [3/10], Step [100]\n",
            "VAE Loss: 312.5559, G Loss: 5.5982, D Loss: 0.0286\n",
            "Ensemble Loss: 0.4435\n",
            "Weights: VAE=0.61, GAN=0.39\n",
            "\n",
            "Epoch [3/10], Step [200]\n",
            "VAE Loss: 315.4785, G Loss: 6.0607, D Loss: 0.0131\n",
            "Ensemble Loss: 0.4516\n",
            "Weights: VAE=0.62, GAN=0.38\n",
            "\n",
            "Epoch [3/10], Step [300]\n",
            "VAE Loss: 318.7615, G Loss: 6.0388, D Loss: 0.0097\n",
            "Ensemble Loss: 0.4603\n",
            "Weights: VAE=0.62, GAN=0.38\n",
            "\n",
            "Epoch [3/10], Step [400]\n",
            "VAE Loss: 288.4370, G Loss: 5.2683, D Loss: 0.0124\n",
            "Ensemble Loss: 0.4266\n",
            "Weights: VAE=0.63, GAN=0.37\n",
            "\n",
            "Epoch [3/10], Step [500]\n",
            "VAE Loss: 294.4205, G Loss: 5.5235, D Loss: 0.0724\n",
            "Ensemble Loss: 0.4200\n",
            "Weights: VAE=0.63, GAN=0.37\n",
            "\n",
            "Epoch [3/10], Step [600]\n",
            "VAE Loss: 290.9914, G Loss: 6.0381, D Loss: 0.0056\n",
            "Ensemble Loss: 0.4157\n",
            "Weights: VAE=0.64, GAN=0.36\n",
            "\n",
            "Epoch [3/10], Step [700]\n",
            "VAE Loss: 270.5991, G Loss: 5.5812, D Loss: 0.0099\n",
            "Ensemble Loss: 0.3852\n",
            "Weights: VAE=0.64, GAN=0.36\n",
            "\n",
            "Epoch [3/10], Step [800]\n",
            "VAE Loss: 291.5120, G Loss: 6.1849, D Loss: 0.0095\n",
            "Ensemble Loss: 0.4152\n",
            "Weights: VAE=0.65, GAN=0.35\n",
            "\n",
            "Epoch [3/10], Step [900]\n",
            "VAE Loss: 304.4891, G Loss: 5.3426, D Loss: 0.0106\n",
            "Ensemble Loss: 0.4158\n",
            "Weights: VAE=0.65, GAN=0.35\n",
            "\n",
            "Epoch [4/10], Step [0]\n",
            "VAE Loss: 281.5456, G Loss: 5.6197, D Loss: 0.0132\n",
            "Ensemble Loss: 0.3890\n",
            "Weights: VAE=0.65, GAN=0.35\n",
            "\n",
            "Epoch [4/10], Step [100]\n",
            "VAE Loss: 292.1083, G Loss: 5.0169, D Loss: 0.0795\n",
            "Ensemble Loss: 0.4023\n",
            "Weights: VAE=0.66, GAN=0.34\n",
            "\n",
            "Epoch [4/10], Step [200]\n",
            "VAE Loss: 281.0428, G Loss: 5.3515, D Loss: 0.0101\n",
            "Ensemble Loss: 0.3840\n",
            "Weights: VAE=0.66, GAN=0.34\n",
            "\n",
            "Epoch [4/10], Step [300]\n",
            "VAE Loss: 274.4923, G Loss: 5.5885, D Loss: 0.0219\n",
            "Ensemble Loss: 0.3782\n",
            "Weights: VAE=0.66, GAN=0.34\n",
            "\n",
            "Epoch [4/10], Step [400]\n",
            "VAE Loss: 266.9179, G Loss: 5.5348, D Loss: 0.0318\n",
            "Ensemble Loss: 0.3655\n",
            "Weights: VAE=0.67, GAN=0.33\n",
            "\n",
            "Epoch [4/10], Step [500]\n",
            "VAE Loss: 272.1901, G Loss: 5.7828, D Loss: 0.0057\n",
            "Ensemble Loss: 0.3662\n",
            "Weights: VAE=0.67, GAN=0.33\n",
            "\n",
            "Epoch [4/10], Step [600]\n",
            "VAE Loss: 276.0578, G Loss: 6.3292, D Loss: 0.0070\n",
            "Ensemble Loss: 0.3896\n",
            "Weights: VAE=0.68, GAN=0.32\n",
            "\n",
            "Epoch [4/10], Step [700]\n",
            "VAE Loss: 287.3264, G Loss: 5.9925, D Loss: 0.0138\n",
            "Ensemble Loss: 0.4013\n",
            "Weights: VAE=0.68, GAN=0.32\n",
            "\n",
            "Epoch [4/10], Step [800]\n",
            "VAE Loss: 260.0298, G Loss: 7.1442, D Loss: 0.0066\n",
            "Ensemble Loss: 0.3652\n",
            "Weights: VAE=0.68, GAN=0.32\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-3ab420f8f36e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# cnn.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtraining_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-97-eead71f85d0e>\u001b[0m in \u001b[0;36mtraining_simulation\u001b[0;34m(config, dataset)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mvae_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vae_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logvar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mvae_loss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = fetch_mnist()\n",
        "\n",
        "config = {\n",
        "\n",
        "    'input_dim': train_dataset.data.shape[1] * train_dataset.data.shape[2],\n",
        "    'latent_dim': 20,\n",
        "    'noise_dim': 100,\n",
        "    'lr': 0.0001,\n",
        "    'num_channels': 1,\n",
        "    'num_classes': len(train_dataset.classes),\n",
        "    'img_size': 28,\n",
        "    'num_epochs': 10,\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "# cnn = CNN(config=config).to(config['device'])\n",
        "# cnn.train()\n",
        "\n",
        "training_simulation(config, train_dataset)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "167Oelj9gCG3p6dCU_tYMmK_9J5TCagEF",
      "authorship_tag": "ABX9TyMt46+y/hj4ecT2b8HR3mDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}